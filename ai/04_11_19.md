DL formally specify meaning of kb

- knowledge is correct (it captures the intuition)
- knowledge is minimally redundant (no unintended synonyms)
- knowledge is meaningful (classes can have instances): it is satisfiable wrt the ontology O?

We can query the KB:

- is x instance of C wrt O?
- is (x,y) instacne of R wrt O?

## Reasoning

- Tableau algo used to test the satisfiability
- Try to build a tree-like model of the input concept C
- Decompose C syntactically
- Tableau rules correspond to constructors in logic
- Stop when no more rules applicable or calsh occurs (obvious contradiction)
- C satisfiable iff rules can be applied such that a fully expanded clash free tree is constructed

## OWL reasoning

Poor when it comes to use the functions, like sum of prices 
So we complement OWL with Rule Language (Semantic Web Rule Language), but it's not decidable
But exists dialects, like datalog, that can complement OWL and is decidable

# Interpreting agents

Reasoning we want to make inference on top of a knowledge base, but an agent must be able to communicate with other agents
Every agent has its own representation of the world, so we must be able to **align** KBs and **integrate** KBs

## How to build a KB?

Suppose we have two different kb written with the same language (OWL, RDFS, ...), how we can align them?

1. Keep both separated and create mappings between one another. 
2. Merge both into one large KB (using mappings)

Exists two different types of mappings:

- Schema level (ontology matching, mappings between concepts and properties)
- Instance level (mappings between entity)

## Ontology matching

We want to align conceptualization, find correspondence between entities belonging to different ontologies
A mapping is mapping = (source entity, target entity, relation, similarity/confidence)
An alignment or matching is a set of mappings
We have a problem on the mapping cardinality, based on the type of the relation
There're a lot of methods:

- Concept based
  - String based (edit distance)
  - Language based (tokenization)
  - Constraint based (types, cardinality)
  - Linguistic (wordnet)
- Structure based
  - Taxonomy and graph based
  - Model based (logic techniques)
- Instance based

## Instance matching

$$
    \sigma(s,t) = \sigma_1(s.p_1, t.p_1) \cdot w_1 + ... + \sigma_n(s.p_n, t.p_n) \cdot w_n \\
    \sum_{i=1}^n \sigma_i(s.p_i, t.p_i) \cdot w_i
$$
given:
- similarity measures $\sigma_i$ for each property $p_i$
- a threshold $\theta$

Create link $(s,t)$ if $\sigma(s,t) \ge \theta$
Problems: scalability; before we do blocking techniques: we select a subgroup of possible candidates
